nn:
  constructor:
    batch_size: 100
    epochs: 5
  fit: {}
  tuning_hyperparams: {}
svm:
  constructor:
    C: 0.1
    gamma: 0.1
  fit: {}
  tuning_hyperparams:
    gamma: [1e1, 1e0, 1e-1, 1e-2, 1e-3, 1e-4, 1e-5]
    C: [00.1, 0.1, 1, 10, 100, 1000]
xgb:
  constructor:
    learning_rate: 0.05
    silent: 1
    seed: 4
    objective: "binary:logistic"
    min_child_weight: 5
    colsample_bytree: 0.8
    colsample_bylevel: 0.9
    max_depth: 6
    subsample: 0.9
    max_delta_step: 10
    gamma: 2
    reg_alpha: 0
    reg_lambda: 1
  fit:
    eval_metric: auc
    verbose: True
  tuning_hyperparams:
    gamma: [1.5, 2, 2.5]
    learning_rate: [0.05, 0.1]
xgbBagged:
  constructor:
    n_estimators: 5
  fit: {}
  tuning_hyperparams: {}
nnBagged:
  constructor:
    n_estimators: 5
  fit: {}
  tuning_hyperparams: {}
logisticRegression:
  constructor: {}
  fit: {}
  tuning_hyperparams: {}
logisticRegressionBagged:
  constructor:
    n_estimators: 5
  fit: {}
  tuning_hyperparams: {}
